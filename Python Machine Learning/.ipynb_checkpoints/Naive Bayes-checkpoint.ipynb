{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabSet = set([])\n",
    "postingList1 = ['my', 'my', 'dog', 'has', 'flea', 'problems', 'help', 'please']\n",
    "postingList2 = ['cat','is','cute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flea', 'my', 'help', 'problems', 'please', 'dog', 'has'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSet = vocabSet|set(postingList1)\n",
    "print(vocabSet)\n",
    "len(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flea', 'is', 'cat', 'my', 'help', 'problems', 'please', 'cute', 'dog', 'has'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabSet = vocabSet|set(postingList2)\n",
    "print(vocabSet)\n",
    "len(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LoadDataset():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    #classVec = [0,1,0,1,0,1]\n",
    "    classVec = ['non','abu','non','abu','non','abu']\n",
    "    return postingList, classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test, Abusive = LoadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
      "['non', 'abu', 'non', 'abu', 'non', 'abu']\n"
     ]
    }
   ],
   "source": [
    "print(Test)\n",
    "print(Abusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateVocabulary(DataSet):\n",
    "    vocab = set([])\n",
    "    for line in DataSet:\n",
    "        vocab = vocab|set(line)\n",
    "    return list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['help',\n",
       " 'mr',\n",
       " 'cute',\n",
       " 'worthless',\n",
       " 'steak',\n",
       " 'flea',\n",
       " 'so',\n",
       " 'him',\n",
       " 'not',\n",
       " 'food',\n",
       " 'garbage',\n",
       " 'dog',\n",
       " 'how',\n",
       " 'buying',\n",
       " 'maybe',\n",
       " 'I',\n",
       " 'is',\n",
       " 'please',\n",
       " 'park',\n",
       " 'ate',\n",
       " 'licks',\n",
       " 'quit',\n",
       " 'love',\n",
       " 'stop',\n",
       " 'dalmation',\n",
       " 'posting',\n",
       " 'to',\n",
       " 'my',\n",
       " 'take',\n",
       " 'problems',\n",
       " 'stupid',\n",
       " 'has']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CreateVocabulary(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VocabToVec(vocab, message):\n",
    "    returnVec = [0]*len(vocab)\n",
    "    for word in message:\n",
    "        if word in vocab:\n",
    "            returnVec[vocab.index(word)]=1\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = CreateVocabulary(Test)\n",
    "ddd = VocabToVec(vocab, Test[0])\n",
    "ddd[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClassProb(classVec, DataSet):\n",
    "        countClass = {}\n",
    "        ClassProb = {}\n",
    "        uniqueClass = list(set(classVec))\n",
    "        for clas in uniqueClass:\n",
    "            countClass[clas]=countClass.get(clas,0)+classVec.count(clas)\n",
    "            ClassProb[clas]=ClassProb.get(clas,0)+countClass[clas]/len(classVec)\n",
    "        return countClass,ClassProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WordProb(DataSet, vocab, classVec):\n",
    "    uniqueClass = list(set(classVec))\n",
    "    numClass = [0]*len(uniqueClass)\n",
    "    \n",
    "    for i in range(len(DataSet)):\n",
    "        numClass[uniqueClass.index(classVec[i])] += len(DataSet[i])  # How many words in each class\n",
    "    totalnum=sum(numClass)   # Number of total words\n",
    "    \n",
    "    wordCount = {}\n",
    "    wordProb = {}\n",
    "    wordClassProb = {}\n",
    "    for word in vocab:\n",
    "        num = [0]*len(uniqueClass)\n",
    "        \n",
    "        for i in range(len(DataSet)):\n",
    "            #print(uniqueClass)\n",
    "            #print(classVec[i])\n",
    "            num[uniqueClass.index(classVec[i])]+=DataSet[i].count(word)\n",
    "                \n",
    "        wordCount[word]=wordCount.get(word,num) # Count 'word' occurence in each class\n",
    "        wordClassProb[word]=list(np.divide(np.array(wordCount[word]),np.array(numClass))) # Conditional Prob\n",
    "        wordProb[word]=sum(wordCount[word])/totalnum # total prob\n",
    "    return wordCount, wordProb, wordClassProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'I': [0, 1],\n",
       "  'ate': [0, 1],\n",
       "  'buying': [1, 0],\n",
       "  'cute': [0, 1],\n",
       "  'dalmation': [0, 1],\n",
       "  'dog': [2, 1],\n",
       "  'flea': [0, 1],\n",
       "  'food': [1, 0],\n",
       "  'garbage': [1, 0],\n",
       "  'has': [0, 1],\n",
       "  'help': [0, 1],\n",
       "  'him': [1, 2],\n",
       "  'how': [0, 1],\n",
       "  'is': [0, 1],\n",
       "  'licks': [0, 1],\n",
       "  'love': [0, 1],\n",
       "  'maybe': [1, 0],\n",
       "  'mr': [0, 1],\n",
       "  'my': [0, 3],\n",
       "  'not': [1, 0],\n",
       "  'park': [1, 0],\n",
       "  'please': [0, 1],\n",
       "  'posting': [1, 0],\n",
       "  'problems': [0, 1],\n",
       "  'quit': [1, 0],\n",
       "  'so': [0, 1],\n",
       "  'steak': [0, 1],\n",
       "  'stop': [1, 1],\n",
       "  'stupid': [3, 0],\n",
       "  'take': [1, 0],\n",
       "  'to': [1, 1],\n",
       "  'worthless': [2, 0]},\n",
       " {'I': 0.023255813953488372,\n",
       "  'ate': 0.023255813953488372,\n",
       "  'buying': 0.023255813953488372,\n",
       "  'cute': 0.023255813953488372,\n",
       "  'dalmation': 0.023255813953488372,\n",
       "  'dog': 0.06976744186046512,\n",
       "  'flea': 0.023255813953488372,\n",
       "  'food': 0.023255813953488372,\n",
       "  'garbage': 0.023255813953488372,\n",
       "  'has': 0.023255813953488372,\n",
       "  'help': 0.023255813953488372,\n",
       "  'him': 0.06976744186046512,\n",
       "  'how': 0.023255813953488372,\n",
       "  'is': 0.023255813953488372,\n",
       "  'licks': 0.023255813953488372,\n",
       "  'love': 0.023255813953488372,\n",
       "  'maybe': 0.023255813953488372,\n",
       "  'mr': 0.023255813953488372,\n",
       "  'my': 0.06976744186046512,\n",
       "  'not': 0.023255813953488372,\n",
       "  'park': 0.023255813953488372,\n",
       "  'please': 0.023255813953488372,\n",
       "  'posting': 0.023255813953488372,\n",
       "  'problems': 0.023255813953488372,\n",
       "  'quit': 0.023255813953488372,\n",
       "  'so': 0.023255813953488372,\n",
       "  'steak': 0.023255813953488372,\n",
       "  'stop': 0.046511627906976744,\n",
       "  'stupid': 0.06976744186046512,\n",
       "  'take': 0.023255813953488372,\n",
       "  'to': 0.046511627906976744,\n",
       "  'worthless': 0.046511627906976744},\n",
       " {'I': [0.0, 0.041666666666666664],\n",
       "  'ate': [0.0, 0.041666666666666664],\n",
       "  'buying': [0.052631578947368418, 0.0],\n",
       "  'cute': [0.0, 0.041666666666666664],\n",
       "  'dalmation': [0.0, 0.041666666666666664],\n",
       "  'dog': [0.10526315789473684, 0.041666666666666664],\n",
       "  'flea': [0.0, 0.041666666666666664],\n",
       "  'food': [0.052631578947368418, 0.0],\n",
       "  'garbage': [0.052631578947368418, 0.0],\n",
       "  'has': [0.0, 0.041666666666666664],\n",
       "  'help': [0.0, 0.041666666666666664],\n",
       "  'him': [0.052631578947368418, 0.083333333333333329],\n",
       "  'how': [0.0, 0.041666666666666664],\n",
       "  'is': [0.0, 0.041666666666666664],\n",
       "  'licks': [0.0, 0.041666666666666664],\n",
       "  'love': [0.0, 0.041666666666666664],\n",
       "  'maybe': [0.052631578947368418, 0.0],\n",
       "  'mr': [0.0, 0.041666666666666664],\n",
       "  'my': [0.0, 0.125],\n",
       "  'not': [0.052631578947368418, 0.0],\n",
       "  'park': [0.052631578947368418, 0.0],\n",
       "  'please': [0.0, 0.041666666666666664],\n",
       "  'posting': [0.052631578947368418, 0.0],\n",
       "  'problems': [0.0, 0.041666666666666664],\n",
       "  'quit': [0.052631578947368418, 0.0],\n",
       "  'so': [0.0, 0.041666666666666664],\n",
       "  'steak': [0.0, 0.041666666666666664],\n",
       "  'stop': [0.052631578947368418, 0.041666666666666664],\n",
       "  'stupid': [0.15789473684210525, 0.0],\n",
       "  'take': [0.052631578947368418, 0.0],\n",
       "  'to': [0.052631578947368418, 0.041666666666666664],\n",
       "  'worthless': [0.10526315789473684, 0.0]})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = WordProb(Test, vocab, Abusive)\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset is training dataset and message is the sentence that we need to test\n",
    "def BayesianProb(DataSet, classVec, message):\n",
    "    \n",
    "    vocab = CreateVocabulary(DataSet)\n",
    "    countClass,classProb = ClassProb(classVec, DataSet)\n",
    "    wordCount, wordProb, wordClassProb = WordProb(DataSet, vocab, classVec)\n",
    "    \n",
    "    indexVec = VocabToVec(vocab, message) #[0,1] vector to show which word appear in message\n",
    "    numOccurence = indexVec.count(1) #How many word form message occur in vocabulary\n",
    "    argsortIndexVec = np.array(indexVec).argsort() # put all '1' at the end of the indexVec\n",
    "    whichWords = argsortIndexVec[-numOccurence:] # find out the index of occurred words\n",
    "    OccurredWords = [vocab[i] for i in whichWords] # the list of occurred words\n",
    "    print(OccurredWords)\n",
    "    \n",
    "    # ???\n",
    "#     Denominator = 1 \n",
    "#     for word in OccurredWords:\n",
    "#         Denominator = Denominator*wordProb[word]  # Logrithm the probability, or the product will be too small\n",
    "#     print(Denominator)\n",
    "    \n",
    "    uniqueClass = list(set(classVec))\n",
    "    print(uniqueClass)\n",
    "    numerators = [0]*len(uniqueClass)\n",
    "    for i in range(len(uniqueClass)):\n",
    "        P_Ci = np.log(classProb[uniqueClass[i]])\n",
    "        print(P_Ci)\n",
    "        product_P_WjCi = P_Ci\n",
    "        for word in OccurredWords:\n",
    "            product_P_WjCi = product_P_WjCi + np.log(wordClassProb[word][i])\n",
    "        print(product_P_WjCi)\n",
    "        numerators[i] = product_P_WjCi\n",
    "    print(numerators)\n",
    "    \n",
    "    BayProbNumerator = numerators\n",
    "    #prediction = uniqueClass.index(max(numerators))\n",
    "\n",
    "    return BayProbNumerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cute', 'my', 'love', 'so', 'him', 'is', 'dalmation', 'I']\n",
      "['abu', 'non']\n",
      "-0.69314718056\n",
      "-inf\n",
      "-0.69314718056\n",
      "-24.3258183541\n",
      "[-inf, -24.325818354115455]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yisongdong/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:29: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-inf, -24.325818354115455]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BayesianProb(Test, Abusive, Test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x10bcafbf8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic['a'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [5, 6], 'b': [0, 0]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25,  0.4 ,  0.5 ])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(np.array([1,2,3]),np.array([4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 24, 23, 22, 21, 20, 19, 18, 16, 30, 14, 25, 13, 28, 10,  9,  8,\n",
       "        7,  6,  4,  3,  2,  1, 12, 26, 27, 29,  0, 11,  5, 17, 31])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ddd).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'problems', 'help', 'dog', 'flea', 'please', 'has']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
